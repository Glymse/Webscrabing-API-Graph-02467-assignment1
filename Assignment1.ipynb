{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5a669d0",
   "metadata": {},
   "source": [
    "# Contribution table with estimated percentage of contribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f182530c",
   "metadata": {},
   "source": [
    "|           | Jonas (s234845) | Alexander(s234815) | Mikkel (s224187) |\n",
    "|-----------|-------|-----------|--------|\n",
    "| **Part 1** |   40%    |   60%        |     0%   |\n",
    "| **Part 2** |   60%    |   40%        |    0%    |\n",
    "| **Part 3** |    80%   |     20%      |    0%    |\n",
    "| **Part 4** |  20%     |      80%     |     0%   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54c3082",
   "metadata": {},
   "source": [
    "We have had minor contact with mikkel, but he has not responded to any invitation prior to that. We have written both on mail and messenger.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f02e89b",
   "metadata": {},
   "source": [
    "Link to the github: https://github.com/Glymse/Webscrabing-API-Graph-02467-assignment1/blob/master/Assignment1.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ae2b05",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fb710fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "from thefuzz import fuzz\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dde4d08",
   "metadata": {},
   "source": [
    "Utility functions, they are being used thoughout the document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4a5afcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful helper functions\n",
    "# Created after the fact to clean up the messy code and to improve readability\n",
    "def fetch_soup(url):\n",
    "    response = requests.get(url)\n",
    "    return BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "def extract_text(elements):\n",
    "    return [el.get_text(strip=True) for el in elements]\n",
    "\n",
    "def split_and_strip(text, separator=','):\n",
    "    # also strips whitespace\n",
    "    return [part.strip() for part in text.split(separator)]\n",
    "\n",
    "def clean_names(names):\n",
    "    # split by comma and flatten to a cleaned list\n",
    "    return list(set([name.strip() for entry in names for name in entry.split(\",\")]))\n",
    "\n",
    "def find_dupe_names(names, threshold=85):\n",
    "    # note: 85 seemed to do pretty well\n",
    "    # 80 was too non-strict\n",
    "    names = sorted(names)\n",
    "    name_matches = {}\n",
    "    remaining_names = set(names)\n",
    "    \n",
    "    for i, name in enumerate(names):\n",
    "        if name not in remaining_names:\n",
    "            continue\n",
    "        \n",
    "        alternatives = [alt_name for alt_name in names[i+1:] if fuzz.ratio(name, alt_name) >= threshold]\n",
    "        remaining_names -= set(alternatives)\n",
    "        name_matches[name] = alternatives if alternatives else \"\" # just leave everything else empty\n",
    "    \n",
    "    # here we create an additional column with a list of the name matches, in case we need to use them later\n",
    "    return pd.DataFrame({'Original': name_matches.keys(), 'Alternatives': name_matches.values()}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2182d781-3727-4ff5-9b58-689381202a99",
   "metadata": {},
   "source": [
    "## Part 1: Web-scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c872832",
   "metadata": {},
   "source": [
    "### 1.1-1.2: Get names of researchers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19043853",
   "metadata": {},
   "source": [
    "The task is to gather researcher names from ic2s2-2023:\n",
    "- Keynote speakers\n",
    "- Plenary\n",
    "- Chairs\n",
    "- Posters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e7f0a388",
   "metadata": {},
   "outputs": [],
   "source": [
    "LINK = \"https://ic2s2-2023.org/program\"\n",
    "\n",
    "# create a list of researcher names that we will append to later\n",
    "researcher_names = []\n",
    "\n",
    "soup_main = fetch_soup(LINK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a27c1d0",
   "metadata": {},
   "source": [
    "#### Keynote names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663aa25f",
   "metadata": {},
   "source": [
    "Keynote speakers all had `keynotes#` in their ref tag/value, so by filtering the href and the `a` name its possible to extract them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c0d926c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keynote_attrs = {'href': re.compile(r'keynotes#')}\n",
    "\n",
    "keynote_html = soup_main.find_all(name=\"a\", attrs=keynote_attrs)\n",
    "\n",
    "# here we use regular expressions and filter for entries starting with \"Keynote -\"\n",
    "keynote_names = [re.sub(r'^Keynote -', '', name).strip() for name in extract_text(keynote_html)]\n",
    "\n",
    "len(keynote_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2798920a",
   "metadata": {},
   "source": [
    "#### Plenary, Chair and Posters names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe1b79e",
   "metadata": {},
   "source": [
    "The rest of the names could all be narrowed down to the `i` name/tag and by doing extra filtering on the `u` tag, its possible to isolate all the names easily. Note that chair members had \"`Chair :`\" in front of them, so you need to delimit that for those entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c3d9f0ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2095"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_tags = soup_main.find_all(name='i')\n",
    "\n",
    "plenary_names = []\n",
    "\n",
    "for tag in author_tags:\n",
    "    u_names = extract_text(tag.find_all('u'))\n",
    "    plain_text_names = re.split(r',\\s*', tag.get_text(strip=True))\n",
    "    plain_text_names = [name for name in plain_text_names if name not in u_names]\n",
    "    # here we use regular expressions and filter for entries starting with \"Chair :\"\n",
    "    plain_text_names = [re.sub(r'^Chair:\\s*', '', name) for name in plain_text_names]\n",
    "    plenary_names.extend(u_names + plain_text_names)\n",
    "\n",
    "len(plenary_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27149b25",
   "metadata": {},
   "source": [
    "#### Program committee names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614bfa66",
   "metadata": {},
   "source": [
    "The program committee names were found in another link/URL. So a new separate soup had to be made for this task. The names in the program committee were found under the `b` name/tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a45a5bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "335"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LINK_comittee = \"https://ic2s2-2023.org/program_committee\"\n",
    "soup_committee = fetch_soup(LINK_comittee)\n",
    "\n",
    "committee_names = extract_text(soup_committee.find_all(\"b\"))\n",
    "\n",
    "len(committee_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3815135f",
   "metadata": {},
   "source": [
    "#### Compilation of all names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44962a14",
   "metadata": {},
   "source": [
    "Now its possible to compile all the names into one list. Then make the list into a set to remove any identical elements (in this case names) and then turn it back into a list. Additionally, delimiting is used on any entries with comma, and then flatten any entry with multiple names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0b7280c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Marton Karsai'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1655"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "researcher_names.extend(keynote_names + plenary_names + committee_names)\n",
    "\n",
    "researcher_names = clean_names(researcher_names)\n",
    "\n",
    "display(researcher_names[0], len(researcher_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a59e43",
   "metadata": {},
   "source": [
    "### 1.3: Filter names, remove duplicates etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03c74d2",
   "metadata": {},
   "source": [
    "Here Fuzzy string matching (`thefuzz`) is used, which utilizes the Levenshtein distance (see [Wikipedia](https://en.wikipedia.org/wiki/Levenshtein_distance#Definition)) metric for measuring the difference between two strings. Note that the number of alternatives depend on the set threshold. Through trial and error we figured a similarity score of 80-85 was adequate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "878389b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original</th>\n",
       "      <th>Alternatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aaron Clauset</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aaron J. Schwartz</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aaron Schein</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aaron Smith</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abbas Haidar</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>Zoltan Kmetty</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>Zsófia Rakovics</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>diogo pacheco</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>franco scarselli</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>salvatore Citraro</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Original Alternatives\n",
       "0         Aaron Clauset             \n",
       "1     Aaron J. Schwartz             \n",
       "2          Aaron Schein             \n",
       "3           Aaron Smith             \n",
       "4          Abbas Haidar             \n",
       "...                 ...          ...\n",
       "1595      Zoltan Kmetty             \n",
       "1596    Zsófia Rakovics             \n",
       "1597      diogo pacheco             \n",
       "1598   franco scarselli             \n",
       "1599  salvatore Citraro             \n",
       "\n",
       "[1600 rows x 2 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "researcher_names_cleaned = find_dupe_names(researcher_names)\n",
    "researcher_names_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932cfb18",
   "metadata": {},
   "source": [
    "Using this method, 55 duplicate names were \"cleared\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "649f2c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original</th>\n",
       "      <th>Alternatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Alessandro Flamini</td>\n",
       "      <td>[Alessandro Flammini]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Alexander Gates</td>\n",
       "      <td>[Alexander J Gates]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ana Maria Jaramillo</td>\n",
       "      <td>[Ana María Jaramillo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>AnnaSeo Gyeong Choi</td>\n",
       "      <td>[Seo Gyeong Choi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Anne C Kroon</td>\n",
       "      <td>[Anne C. Kroon, Anne Kroon]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Original                 Alternatives\n",
       "49    Alessandro Flamini        [Alessandro Flammini]\n",
       "59       Alexander Gates          [Alexander J Gates]\n",
       "95   Ana Maria Jaramillo        [Ana María Jaramillo]\n",
       "139  AnnaSeo Gyeong Choi            [Seo Gyeong Choi]\n",
       "141         Anne C Kroon  [Anne C. Kroon, Anne Kroon]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example where Alternatives is not empty\n",
    "researcher_names_cleaned[researcher_names_cleaned[\"Alternatives\"] != \"\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "528bd992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final length\n",
    "len(researcher_names_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7217231",
   "metadata": {},
   "source": [
    "### 1.6: Explanation of the process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a0cce1",
   "metadata": {},
   "source": [
    "First, the relevant HTML tags associated with researcher names were identified by inspecting the website's elements and navigating through the HTML structure. Specific tags corresponding to names (e.g., u, i) were extracted, and any prefixes or separators unrelated to the actual researcher name were removed, such as \"Chair: \" before chair members of a given plenary or \"Keynote - \" before keynote presenters. To address duplicated or misspelled names, FuzzySearch was applied to compute similarity scores for each name against all other unchecked names."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac17914c-f125-4f70-b1a5-0c56641a0ea0",
   "metadata": {},
   "source": [
    "## Part 2: Ready Made vs Custom Made Data\n",
    "Week 2, ex 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25059f1b-25c3-47eb-8278-903bd7608576",
   "metadata": {},
   "source": [
    "> **Exercise: Ready made data vs Custom made data** In this exercise, I want to make sure you have understood they key points of my lecture and the reading. \n",
    ">\n",
    "> 1. What are pros and cons of the custom-made data used in Centola's experiment (the first study presented in the lecture) and the ready-made data used in Nicolaides's study (the second study presented in the lecture)? You can support your arguments based on the content of the lecture and the information you read in Chapter 2.3 of the book __(answer in max 150 words)__.\n",
    "> 2. How do you think these differences can influence the interpretation of the results in each study? __(answer in max 150 words)__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f42408",
   "metadata": {},
   "source": [
    "- **Centola's experiment: (custom-made)** Based on controlled email invitations to join a health behavior platform.\n",
    "  - **Pros:**\n",
    "    - Low chance of systematic drifting, the study design, invitations, and procedures are fixed and stable throughout the experiment.\n",
    "    - Prevents incomplete data: Since the platform and network were designed for the study, the data structure is complete and consistent.\n",
    "\n",
    "  - **Cons:**\n",
    "    - Population drifting: Users with fewer connections or less engagement might leave the site over time, affecting network structure and participation\n",
    "    - Dirty data: There is a probability of BOT accounts or one-time accounts.  \n",
    "    - Algorithmically confounded: non-spam mails can end up in spam filthers. \n",
    "    - Reactive: People knew they were in a health study, so their behvaoir might be different. \n",
    "\n",
    "- **Nicolaides' study: (ready-made)** Based on observational Strava activity data.\n",
    "  - **Pros:**\n",
    "    - Big data: Access to the entirety of Strava data.\n",
    "    - Always-on: constantly measures people when they run. and share results\n",
    "    - Low chance of behavoiur drifting. Users consistently log runs for their own purposes (training, competition, habit), so the core behavior of interest (running and sharing) stays stable.\n",
    "    - Non reactive: People didn’t know they were being studied, so behavior is natural. \n",
    "  - **Cons:**\n",
    "    - Non-representative of a greater population. Strava users are not a random sample of the general population; they tend to be more sports-oriented and possibly competitive. (comparing themselves to others)\n",
    "    - Dirty: Data could have errors (GPS mistakes, fake activities)\n",
    "    - Population drifting: Platform updates could change user activity and weather may affect amount of people running. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9661d20f",
   "metadata": {},
   "source": [
    "**PART 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322bf197",
   "metadata": {},
   "source": [
    "> Centolas experiemnt:\n",
    "Since the study and data was designed specifically to test how behaviors spread within specific network structures, and conditions were controlled, it's easier to say \"this network structure (contaigon) caused the behavior to spread\". However the reactive setting (participants knew they were in a health study) makes it harder to assume these findings apply in real-world. Emails ending up in spam might add even futher bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9aacd65",
   "metadata": {},
   "source": [
    "> Nicolaides study: There’s no control over why people run or why they interact with others. Other unseen factors (weather, competitions, personal goals) might drive behavior changes. However the data set is big and non reactive, which could give a realistic picture of the study claim even though theres biases. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654c7606-9542-4ecd-9f6e-1c5e298883d6",
   "metadata": {},
   "source": [
    "## Part 3: Gathering Research Articles using the OpenAlex API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ae2e00",
   "metadata": {},
   "source": [
    "### Get researcher names from IC2S2 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d44f96a",
   "metadata": {},
   "source": [
    "Its possible to simply pull the Google Sheets information straight into `pandas` as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c6747703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull info from Google Sheets directly into pandas\n",
    "def gs_link(spreadsheet_id):\n",
    "    return f\"https://docs.google.com/spreadsheets/d/{spreadsheet_id}/export?format=csv\"\n",
    "\n",
    "# Poster presentations\n",
    "pp_id = \"1tyug6JFNa2BVEBFNXMWiKNKwXOxnOLDR\"\n",
    "df_pp = pd.read_csv(gs_link(pp_id))\n",
    "df_pp\n",
    "\n",
    "# Lightning talks\n",
    "lt_id = \"17NqO1ofBn1SKMC6bhCAF_XsRYgHWagDj\"\n",
    "df_ld = pd.read_csv(gs_link(lt_id))\n",
    "df_ld\n",
    "\n",
    "# Oral panels\n",
    "op_id = \"1PY37V6MRvkr9D-w0liMm3X-QN_i43mv0\"\n",
    "df_op = pd.read_csv(gs_link(op_id))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b1a64f",
   "metadata": {},
   "source": [
    "Inspecting the Google Sheets documents its possible to gather the author names from the various columns (`Poster authors` and `Presentation authors`) in the various data frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1388f0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date', 'Poster title', 'Poster authors', 'Easel assignment']\n",
      "['Date', 'Time', 'Location', 'Presentation title', 'Presentation authors']\n",
      "['Session', 'Date', 'Time', 'Location', 'Session track', 'Presentation title', 'Presentation authors']\n"
     ]
    }
   ],
   "source": [
    "for i in [df_pp, df_ld, df_op]:\n",
    "    print(list(i.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c557f48",
   "metadata": {},
   "source": [
    "To get all names in one place we concatenate these into a single list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "43a27dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_2024 = pd.concat([df_pp['Poster authors'], df_ld['Presentation authors'], df_op['Presentation authors']], axis=0).reset_index(drop=True)\n",
    "\n",
    "authors_2024 = authors_2024.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c4bc44",
   "metadata": {},
   "source": [
    "To see what kind of pattern the data has:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bc190878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hazem Ibrahim, New York University; Talal Rahwan, New York University; Yasir Zaki, New York University Abu Dhabi'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors_2024[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aef3f8",
   "metadata": {},
   "source": [
    "Which tells that the pattern is as such: `author name, institution name`.\n",
    "\n",
    "Very few entries had the alternative pattern: `author name (institution name)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b3784c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_2024_cleaned = []\n",
    "\n",
    "for i in authors_2024:\n",
    "    # Separate authors into \"author, institution\"\n",
    "    a_i_list = re.split(r';\\s*', i)\n",
    "    \n",
    "    # Discard institution and keep only author name\n",
    "    for person in a_i_list:\n",
    "        # replace \"(\" with \",\" to remove them all at once\n",
    "        authors_2024_cleaned.append(person.replace(\"(\", \",\").split(\",\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6f1e30",
   "metadata": {},
   "source": [
    "Get rid of identical name duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "61e520af",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_2024_cleaned = clean_names(authors_2024_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3807bfd",
   "metadata": {},
   "source": [
    "Use FuzzySearch on the list of names to further remove duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "31e4b807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original</th>\n",
       "      <th>Alternatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A. Marthe Möller</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aaron Clauset</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aaron D Nichols</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aaron Schein</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abdul Basit Adeel</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>Zsófia Rakovics</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>Zubair Shafiq</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>diogo pacheco</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>Ákos Huszár</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>Şükrü Atsızelti</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1214 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Original Alternatives\n",
       "0      A. Marthe Möller             \n",
       "1         Aaron Clauset             \n",
       "2       Aaron D Nichols             \n",
       "3          Aaron Schein             \n",
       "4     Abdul Basit Adeel             \n",
       "...                 ...          ...\n",
       "1209    Zsófia Rakovics             \n",
       "1210      Zubair Shafiq             \n",
       "1211      diogo pacheco             \n",
       "1212        Ákos Huszár             \n",
       "1213    Şükrü Atsızelti             \n",
       "\n",
       "[1214 rows x 2 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors_2024_cleaned_dupe = find_dupe_names(authors_2024_cleaned, threshold=85)\n",
    "authors_2024_cleaned_dupe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d864cf8",
   "metadata": {},
   "source": [
    "Down to 1214 after cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45da74e4",
   "metadata": {},
   "source": [
    "### Get author IDs and other relevant info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a13da4",
   "metadata": {},
   "source": [
    "The first step is to retrieve the IDs, along with other relevant details, for each author using the OpenAlex API for authors. Searching by author ID is significantly more reliable than searching by name alone. To increase accuracy, alternative names are also considered when the original name is not found.\n",
    "\n",
    "Due to time constraints, the author ID retrieval process was not optimized to the same extent as the later algorithms. Potential improvements include batching multiple author names together for bulk searches and applying parallelization to increase efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "31b6d541",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ = \"./IC2S2-authors.csv\"\n",
    "\n",
    "# check if file exists\n",
    "if os.path.isfile(file_):\n",
    "   authors_df = pd.read_csv(file_)\n",
    "else:\n",
    "    BASE_URL = \"https://api.openalex.org/authors\"\n",
    "\n",
    "    df = authors_2024_cleaned_dupe\n",
    "\n",
    "    author_data = []  # List to hold dictionary records\n",
    "\n",
    "    # Use a session for connection reuse\n",
    "    with requests.Session() as session:\n",
    "        for index, row in df.iterrows():\n",
    "            name = row[\"Original\"]\n",
    "            alternatives = row[\"Alternatives\"] if isinstance(row[\"Alternatives\"], list) else []\n",
    "\n",
    "            all_names = [name] + alternatives  # Try the Original first, then Alternatives\n",
    "\n",
    "            for author_name in all_names:\n",
    "                params = {\"page\": \"1\", \"per_page\": 1, \"search\": author_name}\n",
    "                try:\n",
    "                    time.sleep(0.1)  # Stay within 10 requests per second limit\n",
    "                    response = session.get(BASE_URL, params=params)\n",
    "                    response.raise_for_status()\n",
    "                    \n",
    "                    json_data = response.json()\n",
    "                    result = json_data.get(\"results\", [])\n",
    "\n",
    "                    if result:\n",
    "                        author = result[0]\n",
    "                        #institutions = author.get(\"last_known_institutions\", [])\n",
    "                        #country = institutions[0].get(\"country_code\", \"N/A\") if institutions else \"N/A\" # assuming this is where to fetch country\n",
    "                        author_data.append({\n",
    "                            \"id\": author[\"id\"].split(\"/\")[-1],\n",
    "                            \"display_name\": author[\"display_name\"],\n",
    "                            #\"country\": country, \n",
    "                            \"works_api_url\": author[\"works_api_url\"],\n",
    "                            \"h_index\": author[\"summary_stats\"][\"h_index\"],\n",
    "                            \"works_count\": author[\"works_count\"]\n",
    "                        })\n",
    "                        break  # Stop searching once a match is found\n",
    "\n",
    "                except requests.exceptions.RequestException as e:\n",
    "                    print(f\"Error fetching data for {author_name}: {e}\")\n",
    "\n",
    "    authors_df = pd.DataFrame(author_data)\n",
    "    authors_df.to_csv(\"IC2S2-authors.csv\", index=False) # save as CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d0ecb4",
   "metadata": {},
   "source": [
    "On a mac M1, it takes around 5 minutes. However as said earlier,  bulk searching using the `|` operator could be used in furher development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5a02424c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>display_name</th>\n",
       "      <th>country</th>\n",
       "      <th>works_api_url</th>\n",
       "      <th>h_index</th>\n",
       "      <th>works_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A5082130337</td>\n",
       "      <td>A. Marthe Möller</td>\n",
       "      <td>NL</td>\n",
       "      <td>https://api.openalex.org/works?filter=author.i...</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A5014647140</td>\n",
       "      <td>Aaron Clauset</td>\n",
       "      <td>US</td>\n",
       "      <td>https://api.openalex.org/works?filter=author.i...</td>\n",
       "      <td>48</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A5089395967</td>\n",
       "      <td>Aaron Nichols</td>\n",
       "      <td>US</td>\n",
       "      <td>https://api.openalex.org/works?filter=author.i...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A5053043999</td>\n",
       "      <td>Aaron J. Schein</td>\n",
       "      <td>US</td>\n",
       "      <td>https://api.openalex.org/works?filter=author.i...</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A5082332656</td>\n",
       "      <td>Abdul Basit Adeel</td>\n",
       "      <td>US</td>\n",
       "      <td>https://api.openalex.org/works?filter=author.i...</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>A5090107603</td>\n",
       "      <td>Zsófia Rakovics</td>\n",
       "      <td>HU</td>\n",
       "      <td>https://api.openalex.org/works?filter=author.i...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>A5100771200</td>\n",
       "      <td>Muhammad Shafiq</td>\n",
       "      <td>PK</td>\n",
       "      <td>https://api.openalex.org/works?filter=author.i...</td>\n",
       "      <td>49</td>\n",
       "      <td>396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>A5087528940</td>\n",
       "      <td>Diogo A. Gomes</td>\n",
       "      <td>SA</td>\n",
       "      <td>https://api.openalex.org/works?filter=author.i...</td>\n",
       "      <td>30</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>A5054348632</td>\n",
       "      <td>Ákos Huszár</td>\n",
       "      <td>HU</td>\n",
       "      <td>https://api.openalex.org/works?filter=author.i...</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>A5093136191</td>\n",
       "      <td>Şükrü Atsızelti</td>\n",
       "      <td>TR</td>\n",
       "      <td>https://api.openalex.org/works?filter=author.i...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1141 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id       display_name country  \\\n",
       "0     A5082130337   A. Marthe Möller      NL   \n",
       "1     A5014647140      Aaron Clauset      US   \n",
       "2     A5089395967      Aaron Nichols      US   \n",
       "3     A5053043999    Aaron J. Schein      US   \n",
       "4     A5082332656  Abdul Basit Adeel      US   \n",
       "...           ...                ...     ...   \n",
       "1136  A5090107603    Zsófia Rakovics      HU   \n",
       "1137  A5100771200    Muhammad Shafiq      PK   \n",
       "1138  A5087528940     Diogo A. Gomes      SA   \n",
       "1139  A5054348632        Ákos Huszár      HU   \n",
       "1140  A5093136191    Şükrü Atsızelti      TR   \n",
       "\n",
       "                                          works_api_url  h_index  works_count  \n",
       "0     https://api.openalex.org/works?filter=author.i...        6           13  \n",
       "1     https://api.openalex.org/works?filter=author.i...       48          284  \n",
       "2     https://api.openalex.org/works?filter=author.i...        2           10  \n",
       "3     https://api.openalex.org/works?filter=author.i...       16           19  \n",
       "4     https://api.openalex.org/works?filter=author.i...        4            9  \n",
       "...                                                 ...      ...          ...  \n",
       "1136  https://api.openalex.org/works?filter=author.i...        2            6  \n",
       "1137  https://api.openalex.org/works?filter=author.i...       49          396  \n",
       "1138  https://api.openalex.org/works?filter=author.i...       30          253  \n",
       "1139  https://api.openalex.org/works?filter=author.i...        5           31  \n",
       "1140  https://api.openalex.org/works?filter=author.i...        1            7  \n",
       "\n",
       "[1141 rows x 6 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a814f5",
   "metadata": {},
   "source": [
    "Total authors found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9e4ff697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1141"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(authors_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8051fce1",
   "metadata": {},
   "source": [
    "### Apply filtering to get relevant authors and works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0d9ffa",
   "metadata": {},
   "source": [
    "It's important to note that we create a new list/dataframe for authors here, since we also need to include all co-authors. Furthermore, the works API has a `countries` tag/value under `authorship` where we can directly pull the country code from, for each author."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd22608a",
   "metadata": {},
   "source": [
    "Include only IC2S2 authors with a total work count between 5 and 5,000:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a7a7027a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortWorkCount = authors_df.loc[(authors_df[\"works_count\"] >= 5) & (authors_df[\"works_count\"] <= 5000)]\n",
    "len(sortWorkCount)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480bb7ab",
   "metadata": {},
   "source": [
    "Create chunks/batches of authors, size 25 to utilise the `filther=author.id: {id_1} | {id_2} | ... |`  operator.  This will limit the amount of request needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d99eacd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A5082130337|A5014647140|A5089395967|A5053043999|A5082332656|A5064296964|A5113886631|A5045620226|A5073592405|A5068763840|A5083303782|A5054913386|A5071293344|A5074354806|A5109586591|A5031106143|A5018574266|A5040820784|A5086011172|A5102415619|A5075314395|A5026854954|A5028932589|A5082554858|A5038976962\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Extract author IDs\n",
    "author_ids = sortWorkCount[\"id\"].to_list()\n",
    "\n",
    "# Step 2: Split into chunks of 25\n",
    "chunk_size = 25\n",
    "chunks = [author_ids[i:i + chunk_size] for i in range(0, len(author_ids), chunk_size)]\n",
    "\n",
    "# Step 3: Format each chunk into a string\n",
    "formatted_chunks = [f'{\"|\".join(chunk)}' for chunk in chunks]\n",
    "\n",
    "# Example chunk\n",
    "print(formatted_chunks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5fe90d",
   "metadata": {},
   "source": [
    "Now we are interessted in even more filthering:\n",
    "- 1. Only take articles with relevant concepts at level 0 \n",
    "- 2. Only articles with less than 10 authors\n",
    "- 3. Only articles with more than 10 citations (done using `filther=cited_by_count:>10`) in next code segmentNow we filter the rest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "272f88ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_relevant_works(data):\n",
    "    # Define relevant Level 0 concepts\n",
    "    social_science_concepts = {\"Sociology\", \"Psychology\", \"Economics\", \"Political science\"}\n",
    "    quantitative_concepts = {\"Mathematics\", \"Physics\", \"Computer science\"}\n",
    "\n",
    "    def is_relevant(work):\n",
    "        \"\"\"Checks if a work has at least one concept from each relevant category.\"\"\"\n",
    "        level_0_concepts = {concept[\"display_name\"] for concept in work.get(\"concepts\", []) if concept[\"level\"] == 0}\n",
    "        return (\n",
    "            any(concept in social_science_concepts for concept in level_0_concepts) and\n",
    "            any(concept in quantitative_concepts for concept in level_0_concepts)\n",
    "        )\n",
    "\n",
    "    # Filter works based on criteria\n",
    "    filtered_works = []\n",
    "    abstracts_dataset = []\n",
    "    authors_dataset = []\n",
    "\n",
    "    for work in data.get(\"results\", []):\n",
    "        if len(work.get(\"authorships\", [])) < 10 and is_relevant(work):\n",
    "            work_entry = {\n",
    "                \"id\": work[\"id\"],\n",
    "                \"publication_year\": work[\"publication_year\"],\n",
    "                \"cited_by_count\": work[\"cited_by_count\"],\n",
    "                \"author_ids\": [authorship[\"author\"][\"id\"].split(\"/\")[-1] for authorship in work[\"authorships\"]]\n",
    "            }\n",
    "            filtered_works.append(work_entry)\n",
    "\n",
    "            abstract_entry = {\n",
    "                \"id\": work[\"id\"],\n",
    "                \"title\": work[\"title\"],\n",
    "                \"abstract_inverted_index\": work.get(\"abstract_inverted_index\", {})\n",
    "            }\n",
    "            abstracts_dataset.append(abstract_entry)\n",
    "\n",
    "            for authorship in work.get(\"authorships\", []):\n",
    "                author = authorship[\"author\"]\n",
    "                author_entry = {\n",
    "                    \"id\": author[\"id\"].split(\"/\")[-1],\n",
    "                    \"display_name\": author[\"display_name\"],\n",
    "                    \"country_code\": authorship[\"countries\"][0] if authorship.get(\"countries\") else None\n",
    "                }\n",
    "                authors_dataset.append(author_entry)\n",
    "\n",
    "    return filtered_works, abstracts_dataset, authors_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6aff2a",
   "metadata": {},
   "source": [
    "The following code is not pretty, but it does in simple terms:\n",
    "\n",
    "1 - Uses cursor-paging on the `https://api.openalex.org/works`, it works by putting `https://api.openalex.org/works&cursor = *`, then the meta object will return a cursor ID for the next page of information, resultating in `https://api.openalex.org/works&cursor = {id_nextpage_cursor}`. Then a while loop keeps looping, until the last cursor ID for the specific work url is ``none``. (thus the last page)\n",
    "\n",
    "2 - Takes care of 200 errors (with empty or invalid responses) and 429 (too any requests). Byt doing a try catch where it will attempt 5 times. \n",
    "\n",
    "3 - Use parralel using joblib, where we use ` n = 9` workers (since OpenALEX has a limit of 10 requests pr second) to prevent 429 errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "242d3b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/glymov/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/glymov/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/glymov/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/glymov/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/glymov/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/glymov/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/glymov/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/glymov/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/glymov/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 429 for A5082130337|A5014647140|A5089395967|A5053043999|A5082332656|A5064296964|A5113886631|A5045620226|A5073592405|A5068763840|A5083303782|A5054913386|A5071293344|A5074354806|A5109586591|A5031106143|A5018574266|A5040820784|A5086011172|A5102415619|A5075314395|A5026854954|A5028932589|A5082554858|A5038976962, retrying...\n",
      "Error 429 for A5034728614|A5010879920|A5069001141|A5086308811|A5019136836|A5016014168|A5070753993|A5101690189|A5114125504|A5024130598|A5067288003|A5100714698|A5093136190|A5070019023|A5100350849|A5066491651|A5009735497|A5027261073|A5091142592|A5073844842|A5076189854|A5021327158|A5014989262|A5059787882|A5057083249, retrying...\n"
     ]
    }
   ],
   "source": [
    "def fetch_data(author_ids):\n",
    "    Workurl = \"https://api.openalex.org/works\"\n",
    "    cursor = \"*\"\n",
    "    page_i = 1\n",
    "    Articles = []\n",
    "    Abstract = []\n",
    "    Authors = []\n",
    "\n",
    "    while cursor:\n",
    "        params = {\n",
    "            \"filter\": f\"author.id:{author_ids},cited_by_count:>10\",\n",
    "            \"per-page\": 200,\n",
    "            \"cursor\": cursor\n",
    "        }\n",
    "\n",
    "        for attempt in range(5):  # Retry up to 5 times\n",
    "            try:\n",
    "                response = requests.get(Workurl, params=params, timeout=3)\n",
    "\n",
    "                if response.status_code != 200:\n",
    "                    print(f\"Error {response.status_code} for {author_ids}, retrying...\")\n",
    "                    time.sleep(2 ** attempt)  # Exponential backoff\n",
    "                    continue\n",
    "\n",
    "                if not response.text.strip():  # Check for empty response\n",
    "                    print(f\"Empty response for {author_ids}, retrying...\")\n",
    "                    time.sleep(2 ** attempt)\n",
    "                    continue\n",
    "\n",
    "                data = response.json()  # Parse JSON\n",
    "                break  # Exit retry loop if successful\n",
    "\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"Request error for {author_ids}: {e}, retrying...\")\n",
    "                time.sleep(2 ** attempt)\n",
    "            except requests.exceptions.JSONDecodeError:\n",
    "                print(f\"JSON decode error for {author_ids}, response: {response.text}, retrying...\")\n",
    "                time.sleep(2 ** attempt)\n",
    "\n",
    "        else:\n",
    "            print(f\"Failed to fetch data for {author_ids} after multiple attempts.\")\n",
    "            return [], [], []\n",
    "\n",
    "        # Call the function\n",
    "        filtered_papers, filtered_abstracts, filtered_authors = filter_relevant_works(data)\n",
    "\n",
    "        # Append results to existing lists\n",
    "        Articles.extend(filtered_papers)\n",
    "        Abstract.extend(filtered_abstracts)\n",
    "        Authors.extend(filtered_authors)\n",
    "\n",
    "        #print(f\"Author Batch Processed, Page {page_i} parsed\")\n",
    "        page_i += 1\n",
    "        cursor = data.get('meta', {}).get('next_cursor')\n",
    "\n",
    "    return Articles, Abstract, Authors\n",
    "\n",
    "# Parallel execution for each batch of authors\n",
    "results = Parallel(n_jobs=9)(delayed(fetch_data)(chunk) for chunk in formatted_chunks)\n",
    "\n",
    "# Merging results from parallel execution\n",
    "Articles = []\n",
    "Abstract = []\n",
    "Authors = []\n",
    "for articles, abstracts, authors in results:\n",
    "    Articles.extend(articles)\n",
    "    Abstract.extend(abstracts)\n",
    "    Authors.extend(authors)\n",
    "\n",
    "with open(\"articles.json\", \"w\") as f:\n",
    "    json.dump(Articles, f, indent=4)\n",
    "\n",
    "with open(\"abstracts.json\", \"w\") as f:\n",
    "    json.dump(Abstract, f, indent=4)\n",
    "\n",
    "with open(\"authors.json\", \"w\") as f:\n",
    "    json.dump(Authors, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5fe7ce",
   "metadata": {},
   "source": [
    "Length before filtering/removing duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e80d6d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49501, 12915, 12915)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Authors), len(Articles), len(Abstract)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327f1746",
   "metadata": {},
   "source": [
    "Then remove the duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e0424afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duplicate articles: 1320\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Count occurrences of article IDs\n",
    "id_counts = Counter(article['id'] for article in Articles)\n",
    "\n",
    "# Find duplicates\n",
    "duplicates = {article_id: count for article_id, count in id_counts.items() if count > 1}\n",
    "print(f\"Total duplicate articles: {sum(duplicates.values()) - len(duplicates)}\")\n",
    "#print(\"Duplicate entries per ID:\", duplicates)\n",
    "\n",
    "# Remove duplicates while keeping the first occurrence\n",
    "seen_ids = set()\n",
    "unique_articles = []\n",
    "unique_abstracts = []\n",
    "\n",
    "for article, abstract in zip(Articles, Abstract):\n",
    "    if article['id'] not in seen_ids:\n",
    "        unique_articles.append(article)\n",
    "        unique_abstracts.append(abstract)\n",
    "        seen_ids.add(article['id'])\n",
    "\n",
    "# Update Articles and Abstract with unique elements\n",
    "Articles_cleaned = unique_articles\n",
    "Abstract_cleaned = unique_abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2b0e82c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duplicate authors: 31788\n"
     ]
    }
   ],
   "source": [
    "# Count occurrences of author IDs\n",
    "id_counts = Counter(author['id'] for author in Authors)\n",
    "\n",
    "# Find duplicates\n",
    "duplicates = {author_id: count for author_id, count in id_counts.items() if count > 1}\n",
    "print(f\"Total duplicate authors: {sum(duplicates.values()) - len(duplicates)}\")\n",
    "#print(\"Duplicate entries per ID:\", duplicates)\n",
    "\n",
    "# Remove duplicates while keeping the first occurrence\n",
    "seen_ids = set()\n",
    "unique_authors = []\n",
    "\n",
    "for author in Authors:\n",
    "    if author['id'] not in seen_ids:\n",
    "        unique_authors.append(author)\n",
    "        seen_ids.add(author['id'])\n",
    "\n",
    "# Update Authors with unique elements\n",
    "Authors_cleaned = unique_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "057b0d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11595, 11595, 17713)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Articles_cleaned), len(Abstract_cleaned), len(Authors_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58102b9",
   "metadata": {},
   "source": [
    "Finally, turn them into pandas dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2dbe82f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles = pd.DataFrame(Articles_cleaned)\n",
    "df_abstract= pd.DataFrame(Abstract_cleaned)\n",
    "df_authors = pd.DataFrame(Authors_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "caadd13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>cited_by_count</th>\n",
       "      <th>author_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://openalex.org/W3103362336</td>\n",
       "      <td>2009</td>\n",
       "      <td>7042</td>\n",
       "      <td>[A5014647140, A5082953212, A5067142016]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://openalex.org/W2047940964</td>\n",
       "      <td>2004</td>\n",
       "      <td>6955</td>\n",
       "      <td>[A5014647140, A5067142016, A5008033989]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://openalex.org/W2018045523</td>\n",
       "      <td>2002</td>\n",
       "      <td>4174</td>\n",
       "      <td>[A5007285525, A5067021466, A5029755266, A50883...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://openalex.org/W2119298903</td>\n",
       "      <td>2012</td>\n",
       "      <td>3872</td>\n",
       "      <td>[A5054913386, A5065660380, A5065503150]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://openalex.org/W1987228002</td>\n",
       "      <td>2010</td>\n",
       "      <td>3047</td>\n",
       "      <td>[A5100744117, A5080830598, A5022334515, A50389...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  publication_year  cited_by_count  \\\n",
       "0  https://openalex.org/W3103362336              2009            7042   \n",
       "1  https://openalex.org/W2047940964              2004            6955   \n",
       "2  https://openalex.org/W2018045523              2002            4174   \n",
       "3  https://openalex.org/W2119298903              2012            3872   \n",
       "4  https://openalex.org/W1987228002              2010            3047   \n",
       "\n",
       "                                          author_ids  \n",
       "0            [A5014647140, A5082953212, A5067142016]  \n",
       "1            [A5014647140, A5067142016, A5008033989]  \n",
       "2  [A5007285525, A5067021466, A5029755266, A50883...  \n",
       "3            [A5054913386, A5065660380, A5065503150]  \n",
       "4  [A5100744117, A5080830598, A5022334515, A50389...  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2167e6bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>display_name</th>\n",
       "      <th>country_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A5014647140</td>\n",
       "      <td>Aaron Clauset</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A5082953212</td>\n",
       "      <td>Cosma Rohilla Shalizi</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A5067142016</td>\n",
       "      <td>M. E. J. Newman</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A5008033989</td>\n",
       "      <td>Cristopher Moore</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A5007285525</td>\n",
       "      <td>Erzsébet Ravasz Regan</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17708</th>\n",
       "      <td>A5083702049</td>\n",
       "      <td>Feng Wang</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17709</th>\n",
       "      <td>A5100452647</td>\n",
       "      <td>Han Wang</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17710</th>\n",
       "      <td>A5004273745</td>\n",
       "      <td>Jinan Luo</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17711</th>\n",
       "      <td>A5109934253</td>\n",
       "      <td>Rongzu Hu</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17712</th>\n",
       "      <td>A5103099529</td>\n",
       "      <td>Bing Jing</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17713 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id           display_name country_code\n",
       "0      A5014647140          Aaron Clauset         None\n",
       "1      A5082953212  Cosma Rohilla Shalizi         None\n",
       "2      A5067142016        M. E. J. Newman         None\n",
       "3      A5008033989       Cristopher Moore           US\n",
       "4      A5007285525  Erzsébet Ravasz Regan           US\n",
       "...            ...                    ...          ...\n",
       "17708  A5083702049              Feng Wang           CN\n",
       "17709  A5100452647               Han Wang           CN\n",
       "17710  A5004273745              Jinan Luo           CN\n",
       "17711  A5109934253              Rongzu Hu           CN\n",
       "17712  A5103099529              Bing Jing           CN\n",
       "\n",
       "[17713 rows x 3 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "56b8809a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract_inverted_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://openalex.org/W3103362336</td>\n",
       "      <td>Power-Law Distributions in Empirical Data</td>\n",
       "      <td>{'Power-law': [0], 'distributions': [1], 'occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://openalex.org/W2047940964</td>\n",
       "      <td>Finding community structure in very large netw...</td>\n",
       "      <td>{'The': [0, 147], 'discovery': [1], 'and': [2,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://openalex.org/W2018045523</td>\n",
       "      <td>Hierarchical Organization of Modularity in Met...</td>\n",
       "      <td>{'Spatially': [0], 'or': [1], 'chemically': [2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://openalex.org/W2119298903</td>\n",
       "      <td>Evaluating Online Labor Markets for Experiment...</td>\n",
       "      <td>{'We': [0, 16, 32, 57, 69], 'examine': [1], 't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://openalex.org/W1987228002</td>\n",
       "      <td>Limits of Predictability in Human Mobility</td>\n",
       "      <td>{'Predictable': [0], 'Travel': [1], 'Routines'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  \\\n",
       "0  https://openalex.org/W3103362336   \n",
       "1  https://openalex.org/W2047940964   \n",
       "2  https://openalex.org/W2018045523   \n",
       "3  https://openalex.org/W2119298903   \n",
       "4  https://openalex.org/W1987228002   \n",
       "\n",
       "                                               title  \\\n",
       "0          Power-Law Distributions in Empirical Data   \n",
       "1  Finding community structure in very large netw...   \n",
       "2  Hierarchical Organization of Modularity in Met...   \n",
       "3  Evaluating Online Labor Markets for Experiment...   \n",
       "4         Limits of Predictability in Human Mobility   \n",
       "\n",
       "                             abstract_inverted_index  \n",
       "0  {'Power-law': [0], 'distributions': [1], 'occu...  \n",
       "1  {'The': [0, 147], 'discovery': [1], 'and': [2,...  \n",
       "2  {'Spatially': [0], 'or': [1], 'chemically': [2...  \n",
       "3  {'We': [0, 16, 32, 57, 69], 'examine': [1], 't...  \n",
       "4  {'Predictable': [0], 'Travel': [1], 'Routines'...  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_abstract.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed416f4a",
   "metadata": {},
   "source": [
    "> To conclude we have:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c79b80",
   "metadata": {},
   "source": [
    "**Data Overview and Reflection questions: Answer the following questions:**\n",
    "\n",
    "- **Dataset summary.** \n",
    "\n",
    "We have 11596 unique articles , with 17713 unique co-authors.  \n",
    "\n",
    "- **Code effeciency.** \n",
    "  \n",
    "To improve efficiency, author IDs were processed in chunks. The filter `cited_by_count:>10` was applied directly within the API request. After retrieval, works were further filtered based on relevant topics and the number of authors. Parallel requests were utilized alongside cursor-based pagination, with the maximum page size of 200 to reduce the number of requests. These optimizations reduced the runtime to just 1.5 minutes on a Mac M1.\n",
    "\n",
    "\n",
    "- **Filtering Criteria and Dataset Relevance**\n",
    "\n",
    "\n",
    "Filtering out authors with fewer than 5 works helps exclude individuals who may not have a substantial influence in social science. Similarly, setting a minimum citation count of 10 helps focus the analysis on works that have made a measurable impact. Since the goal is to study the network of Social-SCI researchers, it's important to highlight the influential works. Papers with large author lists can create oversized clusters in the network, which may obscure the underlying structures. Finally, filtering for works that are explicitly relevant to Social-SCI ensures we are analyzing the right subset of research.\n",
    "\n",
    "\n",
    "However theese filthers, may exclude meta-studies with lots of citations and new studies (with few citations). Which could for example restrict the data to a older time period. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f72dca3-246a-4056-b99c-2f14ccef7fef",
   "metadata": {},
   "source": [
    "## Part 4: The Network of Computational Social Scientists\n",
    "Week 4, ex 1. Please use the final dataset you collected from both authors and co-authors (IC2S2 2024)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8a2df6",
   "metadata": {},
   "source": [
    "### 4.1: Network Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b6efbb",
   "metadata": {},
   "source": [
    "Note that:\n",
    "- Nodes = authors of academic papers\n",
    "- Link/edge = authors A and B have written a paper together (co-authored)\n",
    "- Link weight = number of papers written by both author A and B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21bba67",
   "metadata": {},
   "source": [
    "#### 4.1.1: Weighted Edgelist Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e3f19012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# generate co-author pairs and count occurrences\n",
    "edge_list = []\n",
    "for authors in df_articles['author_ids']:\n",
    "    pairs = list(itertools.combinations(authors, 2))  # make all possible author A-B pairs\n",
    "    edge_list.extend(pairs)\n",
    "\n",
    "# count occurrences of each pair\n",
    "edge_weights = {}\n",
    "for pair in edge_list:\n",
    "    if pair in edge_weights:\n",
    "        edge_weights[pair] += 1\n",
    "    else:\n",
    "        edge_weights[pair] = 1\n",
    "\n",
    "# convert to DataFrame (Weighted Edge List)\n",
    "weighted_edge_list = pd.DataFrame(\n",
    "    [(a, b, w) for (a, b), w in edge_weights.items()],\n",
    "    columns=[\"source\", \"target\", \"weight\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f018ec08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A5014647140</td>\n",
       "      <td>A5082953212</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A5014647140</td>\n",
       "      <td>A5067142016</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A5082953212</td>\n",
       "      <td>A5067142016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A5014647140</td>\n",
       "      <td>A5008033989</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A5067142016</td>\n",
       "      <td>A5008033989</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59770</th>\n",
       "      <td>A5083702049</td>\n",
       "      <td>A5109934253</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59771</th>\n",
       "      <td>A5100452647</td>\n",
       "      <td>A5004273745</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59772</th>\n",
       "      <td>A5100452647</td>\n",
       "      <td>A5109934253</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59773</th>\n",
       "      <td>A5004273745</td>\n",
       "      <td>A5109934253</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59774</th>\n",
       "      <td>A5103099529</td>\n",
       "      <td>A5069259977</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59775 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            source       target  weight\n",
       "0      A5014647140  A5082953212       1\n",
       "1      A5014647140  A5067142016       4\n",
       "2      A5082953212  A5067142016       1\n",
       "3      A5014647140  A5008033989       5\n",
       "4      A5067142016  A5008033989       1\n",
       "...            ...          ...     ...\n",
       "59770  A5083702049  A5109934253       1\n",
       "59771  A5100452647  A5004273745       1\n",
       "59772  A5100452647  A5109934253       1\n",
       "59773  A5004273745  A5109934253       1\n",
       "59774  A5103099529  A5069259977       1\n",
       "\n",
       "[59775 rows x 3 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_edge_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4884018d",
   "metadata": {},
   "source": [
    "#### 4.1.2: Graph Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0c67af45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make undirected graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# add weighted edges\n",
    "G.add_weighted_edges_from(weighted_edge_list.itertuples(index=False, name=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017da917",
   "metadata": {},
   "source": [
    "#### 4.1.3: Node Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2765ac7f",
   "metadata": {},
   "source": [
    "Here, numerical data is converted to `int` as JSON was unable to encode `numpy.int64` datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "750c8ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert authors_df into a dictionary for quick lookup\n",
    "author_metadata = {\n",
    "    row[\"id\"]: {\n",
    "        \"display_name\": row[\"display_name\"],\n",
    "        \"country_code\": row[\"country_code\"]\n",
    "    }\n",
    "    for _, row in df_authors.iterrows()\n",
    "}\n",
    "\n",
    "# Convert df_articles into a dictionary for first_pub_year & citation_count\n",
    "author_publication_info = {}\n",
    "for _, row in df_articles.iterrows():\n",
    "    for author in row[\"author_ids\"]:\n",
    "        if author not in author_publication_info:\n",
    "            author_publication_info[author] = {\n",
    "                \"first_pub_year\": int(row[\"publication_year\"]),  # Convert numpy.int64 to int\n",
    "                \"citation_count\": int(row[\"cited_by_count\"])  # Convert numpy.int64 to int\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "79a56542",
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in G.nodes():\n",
    "    # Get author metadata from authors_df\n",
    "    G.nodes[node][\"display_name\"] = author_metadata.get(node, {}).get(\"display_name\", \"Unknown\")\n",
    "    G.nodes[node][\"country_code\"] = author_metadata.get(node, {}).get(\"country_code\", \"Unknown\")\n",
    "\n",
    "    # Get publication info from df_articles\n",
    "    G.nodes[node][\"first_pub_year\"] = author_publication_info.get(node, {}).get(\"first_pub_year\", None)\n",
    "    G.nodes[node][\"citation_count\"] = author_publication_info.get(node, {}).get(\"citation_count\", 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d181d3a",
   "metadata": {},
   "source": [
    "Example lookup of an author in the graph, programatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "145d0f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'display_name': 'A. Marthe Möller',\n",
       " 'country_code': 'NL',\n",
       " 'first_pub_year': 2017,\n",
       " 'citation_count': 230}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.nodes[\"A5082130337\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc1b72c",
   "metadata": {},
   "source": [
    "Finally save the graph as a JSON file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "79b61ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from networkx.readwrite import json_graph\n",
    "\n",
    "# Convert NetworkX graph to JSON format\n",
    "graph_data = json_graph.node_link_data(G)\n",
    "\n",
    "# Save to a JSON file\n",
    "with open(\"coauthorship_network.json\", \"w\") as f:\n",
    "    json.dump(graph_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4002b12f",
   "metadata": {},
   "source": [
    "### 4.2: Preliminary Network Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22765b3",
   "metadata": {},
   "source": [
    "#### 4.2.1: Network Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcd0363",
   "metadata": {},
   "source": [
    "> What is the total number of nodes (authors) and links (collaborations) in the network? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef0a635",
   "metadata": {},
   "source": [
    "Number of nodes and edges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f99d82ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of nodes (authors): 17704\n",
      "Total number of links (collaborations): 56903\n"
     ]
    }
   ],
   "source": [
    "G_nodes = len(G.nodes())\n",
    "G_edges = len(G.edges())\n",
    "\n",
    "print(f\"Total number of nodes (authors): {G_nodes}\")\n",
    "print(f\"Total number of links (collaborations): {G_edges}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03bcfa4",
   "metadata": {},
   "source": [
    "> Calculate the network's density (the ratio of actual links to the maximum possible number of links). Would you say that the network is sparse? Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4663bc72",
   "metadata": {},
   "source": [
    "To calculate the network's density we need to calculate the maximum possible number of links, which for an undirected graph like this, can be calculated as such:\n",
    "$$\n",
    "E_{\\max} = \\frac{n(n-1)}{2}\n",
    "$$\n",
    "where $n$ are the number of nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "eec20e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156706956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.000363117256900836"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_max = int(G_nodes*(G_nodes-1)/2)\n",
    "print(E_max)\n",
    "\n",
    "ratio_ = G_edges/E_max\n",
    "\n",
    "ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9026f777",
   "metadata": {},
   "source": [
    "The network is sparse, as only 56903 links/edges are established out of 156706956 possible links. This implies that most of the authors have not collaborated or coauthored together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d1ab14",
   "metadata": {},
   "source": [
    "> Is the network fully connected (i.e., is there a direct or indirect path between every pair of nodes within the network), or is it disconnected?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75219e80",
   "metadata": {},
   "source": [
    "No, the network is not fully connected, i.e. it is disconnected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "eaac2bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.is_connected(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5a0a7f",
   "metadata": {},
   "source": [
    "This means that there are clusters of graphs and subgraphs, which also makes sense as people from different backgrounds are less likely to work together unless it's some cross-sectional research."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a89474",
   "metadata": {},
   "source": [
    " If the network is disconnected, how many connected components does it have? A connected component is defined as a subset of nodes within the network where a path exists between any pair of nodes in that subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7e946f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.number_connected_components(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdf1a5a",
   "metadata": {},
   "source": [
    "> How many isolated nodes are there in your network?  An isolated node is defined as a node with no connections to any other node in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f1a51a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, [])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.number_of_isolates(G), list(nx.isolates(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166d3a7e",
   "metadata": {},
   "source": [
    "There are no isolated (degree zero) nodes, meaning no author has never only worked alone in all their papers. In other words, an author may have worked alone on some papers, but have released other papers where they have collaborated with authors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05acae80",
   "metadata": {},
   "source": [
    ">Discuss the results above on network density, and connectivity. Are your findings in line with what you expected? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018add77",
   "metadata": {},
   "source": [
    "Yes, as explained above, the results are as expected as people from different sectors/fields are less likely to work together. If the number of edges were maximized, it would've required all authors to have collaborated with every other author."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bf7452",
   "metadata": {},
   "source": [
    "#### 4.2.2: Degree Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af243c5",
   "metadata": {},
   "source": [
    "> Compute the average, median, mode, minimum, and maximum degree of the nodes. Perform the same analysis for node strength (weighted degree). What do these metrics tell us about the network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5b03e08c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>degree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17704.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.428265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.743540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>362.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             degree\n",
       "count  17704.000000\n",
       "mean       6.428265\n",
       "std       10.743540\n",
       "min        1.000000\n",
       "25%        3.000000\n",
       "50%        5.000000\n",
       "75%        7.000000\n",
       "max      362.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get degrees for all nodes (authors)\n",
    "node_degree = pd.DataFrame.from_dict(G.degree)\n",
    "node_degree.columns = [\"id\", \"degree\"]\n",
    "display(node_degree.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853db48b",
   "metadata": {},
   "source": [
    "Note that the median is the 50% percentile.\n",
    "\n",
    "Generally these metrics give us insight into the collaboration/coauthoring tendencies e.g., that the average author has collaborated with around 6 other authors and that the maximum number of collaborations that an author has done is 362. It's also worth noting that the standard deviation is quite high, which is expected as e.g., general engineers are more \"prone\" to do cross-field papers due to their versatility. The summary statistics also tell us that the distribution of degrees is very likely to be right-skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "eddcdaf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>degree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17704.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.15488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17.13154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>540.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            degree\n",
       "count  17704.00000\n",
       "mean       8.15488\n",
       "std       17.13154\n",
       "min        1.00000\n",
       "25%        3.00000\n",
       "50%        5.00000\n",
       "75%        8.00000\n",
       "max      540.00000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parse the weight property to apply weights\n",
    "node_degree_weighted = pd.DataFrame.from_dict(G.degree(weight=\"weight\"))\n",
    "node_degree_weighted.columns = [\"id\", \"degree\"]\n",
    "display(node_degree_weighted.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246775d4",
   "metadata": {},
   "source": [
    "The weight property on the edges represent the strength of coauthorship, in other words it says something about the frequency or intensity of collaboration. This also weighs in the number of times two authors have worked together, and not just if they have worked together (as in the non-weighted case)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45281db1",
   "metadata": {},
   "source": [
    "#### 4.2.3: Top Authors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba9da82",
   "metadata": {},
   "source": [
    "> Identify the top 5 authors by degree. What role do these node play in the network? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6599f087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>degree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8081</th>\n",
       "      <td>A5100322712</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16297</th>\n",
       "      <td>A5005421447</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8693</th>\n",
       "      <td>A5077712228</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>A5007176508</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4830</th>\n",
       "      <td>A5059645286</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id  degree\n",
       "8081   A5100322712     362\n",
       "16297  A5005421447     306\n",
       "8693   A5077712228     279\n",
       "108    A5007176508     263\n",
       "4830   A5059645286     256"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get top 5 authors\n",
    "top_5 = node_degree.nlargest(5, \"degree\")\n",
    "top_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5a521c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>display_name</th>\n",
       "      <th>country_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8085</th>\n",
       "      <td>A5100322712</td>\n",
       "      <td>Yan Wang</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id display_name country_code\n",
       "8085  A5100322712     Yan Wang           US"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>display_name</th>\n",
       "      <th>country_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16306</th>\n",
       "      <td>A5005421447</td>\n",
       "      <td>Yi Yang</td>\n",
       "      <td>AU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id display_name country_code\n",
       "16306  A5005421447      Yi Yang           AU"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>display_name</th>\n",
       "      <th>country_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8698</th>\n",
       "      <td>A5077712228</td>\n",
       "      <td>Simon A. Levin</td>\n",
       "      <td>GB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id    display_name country_code\n",
       "8698  A5077712228  Simon A. Levin           GB"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>display_name</th>\n",
       "      <th>country_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>A5007176508</td>\n",
       "      <td>Alex Pentland</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id   display_name country_code\n",
       "108  A5007176508  Alex Pentland           US"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>display_name</th>\n",
       "      <th>country_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4832</th>\n",
       "      <td>A5059645286</td>\n",
       "      <td>Robert West</td>\n",
       "      <td>GB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id display_name country_code\n",
       "4832  A5059645286  Robert West           GB"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get their names\n",
    "for id in top_5[\"id\"]:\n",
    "    display(df_authors[df_authors[\"id\"] == id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d5c086",
   "metadata": {},
   "source": [
    "You could say they act as \"author hubs\", and that they have collaborated with a lot of other people.\n",
    "\n",
    "Judging by their OpenAlex author entries, Yan Wang, Yi Wang, Alex Pentland specialize mainly in computer science, AI/ML, and they have some works in the social science subfield. This makes sense as a lot of their data may have roots in social science.\n",
    "\n",
    "Simon A. Levin and Robert West work in health, biology, chemistry and/or environmental engineering with only a few works in computer science. Their big \"footprint\" can probably explain their large degree."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
